{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.태깅 작업(Tagging Task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서는 자연어 처리 분야에서 각 단어가 어떤 유형에 속해있는지를 알아내는 태깅 작업에 대해서 배웁니다. 이러한 단어 태깅 작업은 대표적으로 크게 두 가지가 있는데 각 단어의 유형이 사람, 장소, 단체 등 어떤 유형인지를 알아내는 개체명 인식(Named Entity Recognition)과 각 단어의 품사가 명사, 동사, 형용사 인지를 알아내는 품사 태깅(Part-of-Speech Tagging)이 있습니다.\n",
    "\n",
    "이러한 작업은 챗봇, 기계 번역 등과 같은 자연어 처리 분야에서 메인 작업에 앞서 전처리 작업으로서 필요한 경우가 많지만, 전처리 작업이라고 쉬운 작업이 아니라 그 자체로도 까다로운 작업이 되어 많은 시간을 필요로 하는 작업이 되기도 합니다.\n",
    "\n",
    "여기서는 케라스(Keras)를 이용해서 인공 신경망을 이용한 개체명 인식기와 품사 태거를 만드는 간단한 미니 프로젝트를 수행해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 케라스를 이용한 태깅 작업 개요(Tagging Task using Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 챕터에서는 케라스(Keras)로 인공 신경망을 이용하여 태깅 작업을 하는 모델을 만듭니다. 개체명 인식기와 품사 태거를 만드는데, 이러한 두 작업의 공통점은 RNN의 다-대-다(Many-to-Many) 작업이면서 또한 앞, 뒤 시점의 입력을 모두 참고하는 양방향 RNN(Bidirectional RNN)을 사용한다는 점입니다.\n",
    "\n",
    "두 개의 실습 챕터를 진행하기 전에 전체적으로 실습이 어떻게 진행되는지 정리해보도록 하겠습니다. 텍스트 분류 개요 챕터와 겹치는 부분에 대해서는 요약하여 설명하므로, 이해가 되지 않는 부분이 있다면 해당 챕터를 참고바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 훈련 데이터에 대한 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "태깅 작업은 앞서 배운 텍스트 분류 작업과 동일하게 지도 학습(Supervised Learning)에 속합니다. 이 챕터에서는 태깅을 해야하는 단어 데이터를 X, 레이블에 해당되는 태깅 정보 데이터는 y라고 이름을 붙였습니다. X에 대한 훈련 데이터는 X_train, 테스트 데이터는 X_test라고 명명하고 y에 대한 훈련 데이터는 y_train, 테스트 데이터는 y_test라고 명명합니다.\n",
    "\n",
    "이번 챕터에서 X와 y데이터의 쌍(pair)은 병렬 구조를 가진다는 특징을 가집니다. X와 y의 각 데이터의 길이는 같습니다. 예를 들어 품사 태깅 작업을 한다고 가정해보겠습니다. 그리고 X_train와 y_train의 데이터 중 4개의 데이터만 확인해본다고 가정해보겠습니다. 이 때 데이터는 다음과 같은 구조를 가집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|X_train|y_train|길이|\n",
    "|--------|----------|---------|\n",
    "|0|['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb']|['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O']|8|\n",
    "|1|['peter', 'blackburn']|['B-PER', 'I-PER']|2|\n",
    "|2|['brussels', '1996-08-22' ]|['B-LOC', 'O']|2|\n",
    "|3|['The', 'European', 'Commission']|['O', 'B-ORG', 'I-ORG']|3|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가령, X_train[3]의 'The'와 y_train[3]의 'O'는 하나의 쌍(pair)입니다. 또한, X_train[3]의 'European'과 y_train[3]의 'B-ORG'는 쌍의 관계를 가지며, X_train[3]의 'Commision'과 y_train[3]의 'I-ORG'는 쌍의 관계를 가집니다.\n",
    "\n",
    "이렇게 병렬 관계를 가지는 각 데이터는 정수 인코딩 과정을 거친 후, 모든 데이터의 길이를 동일하게 맞춰주기위한 패딩(Padding) 작업을 거칩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 시퀀스 레이블링(Sequence Labeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 입력 시퀀스 X = [x1, x2, x3, ..., xn]에 대하여 레이블 시퀀스 y = [y1, y2, y3, ..., yn]를 각각 부여하는 작업을 시퀀스 레이블링 작업(Sequence Labeling Task)이라고 합니다. 태깅 작업은 대표적인 시퀀스 레이블링 작업입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 양방향 LSTM(Bidirectional LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.add(Bidirectional(LSTM(hidden_size, return_sequences=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 챕터에서도 바닐라 RNN이 아니라 성능이 개선된 RNN인 LSTM을 사용합니다. 텍스트 분류 챕터에서는 단방향 LSTM을 사용하였지만, 이번 챕터에서는 양방향 LSTM을 사용합니다. 이전 시점의 단어 정보 뿐만 아니라, 다음 시점의 단어 정보도 참고하기 위함입니다. 양방향은 기존의 단방향 LSTM()을 Bidirectional() 안에 넣으면 됩니다.\n",
    "\n",
    "인자 정보는 단방향 LSTM을 사용할 때와 동일합니다. 즉, 인자값을 하나를 줄 경우에는 이는 hidden_size를 의미하며, 결과적으로 output_dim이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. RNN의 다-대-다(Many-to-Many) 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/many_to_one.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN의 은닉층은 모든 시점에 대해서 은닉 상태값을 출력할 수 있고, 마지막 시점에 대해서만 은닉 상태값을 출력할 수 있습니다. 이는 인자로 return_sequences=True를 넣을 것인지, 넣지 않을 것인지로 설정할 수 있는데 태깅 작업의 경우에는 다-대-다(Many-to-Many) 문제로 return_sequences=True를 설정하여 출력층에 모든 은닉 상태값을 보냅니다.\n",
    "\n",
    "이제 RNN이 어떻게 설계되는지 확인해보도록 하겠습니다. 예를 들어 위에서 설명한 데이터 중 첫번째 데이터에 해당되는 X_train[0]를 가지고 4번의 시점(time steps)까지 RNN을 진행하였을 때의 그림은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/forwardrnn_ver2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 이번 실습에서는 양방향 RNN을 사용할 것이므로 아래의 그림과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/bidirectionalrnn_ver2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 개체명 인식(Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 챕터에서는 코퍼스로부터 각 개체(entity)의 유형을 인식하는 개체명 인식(Named Entity Recognition)에 대해서 배웁니다. 개체명 인식을 사용하면 코퍼스로부터 어떤 단어가 사람, 장소, 조직 등을 의미하는 단어인지를 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 개체명 인식(Named Entity Recognition)이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개체명 인식(Named Entity Recognition)이란 말 그대로 이름을 가진 개체(named entity)를 인식하겠다는 것을 의미합니다. 좀 더 쉽게 설명하면, 어떤 이름을 의미하는 단어를 보고는 그 단어가 어떤 유형인지를 인식하는 것을 말합니다.\n",
    "\n",
    "예를 들어 도연이는 2018년에 골드만삭스에 입사했다. 라는 문장이 있을 때, 사람(person), 조직(organization), 시간(time)에 대해 개체명 인식을 수행하는 모델이라면 다음과 같은 결과를 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**도연 - 사람  \n",
    "2018년 - 시간  \n",
    "골드만삭스 - 조직**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서는 우선 개체명 인식의 정의부터 이해하기 위해 중간 과정을 생략했지만 개체명 인식 모델이 개체명을 인식하기 위해서는 보통 전처리 과정이 필요합니다. 개체명 모델에 따라서는 품사 정보(POS Tagging, Part-Of-Speech Tagging)를 입력으로 요구하기도 합니다.\n",
    "\n",
    "예제를 통해 개체명 인식을 이해해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. NLTK를 이용한 개체명 인식(Named Entity Recognition using NTLK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK에서는 개체명 인식기(NER chunker)를 지원하고 있으므로, 별도 개체명 인식기를 구현할 필요없이 NLTK를 사용해서 개체명 인식을 수행할 수 있습니다. 만약 아래의 실습에서 nltk.download('maxent_ne_chunker'), nltk.download('words') 등의 설치를 요구하는 에러 문구가 뜬다면, 지시하는대로 설치하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('James', 'NNP'), ('is', 'VBZ'), ('working', 'VBG'), ('at', 'IN'), ('Disney', 'NNP'), ('in', 'IN'), ('London', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "sentence = \"James is working at Disney in London\"\n",
    "sentence=pos_tag(word_tokenize(sentence))\n",
    "print(sentence) # 토큰화와 품사 태깅을 동시 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON James/NNP)\n",
      "  is/VBZ\n",
      "  working/VBG\n",
      "  at/IN\n",
      "  (ORGANIZATION Disney/NNP)\n",
      "  in/IN\n",
      "  (GPE London/NNP))\n"
     ]
    }
   ],
   "source": [
    "sentence=ne_chunk(sentence)\n",
    "print(sentence) # 개체명 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ne_chunk는 개체명을 태깅하기 위해서 앞서 품사 태깅(pos_tag)이 수행되어야 합니다. 위의 결과에서 James는 PERSON(사람), Disney는 조직(ORGANIZATION), London은 위치(GPE)라고 정상적으로 개체명 인식이 수행된 것을 볼 수 있습니다.\n",
    "\n",
    "이번 챕터에서는 인공 신경망을 이용해서 개체명 인식 모델을 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 양방향 LSTM을 이용한 개체명 인식(Named Entity Recognition using Bi-LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개체명 인식은 챗봇 등에서 필요로 하는 주요 전처리 작업이지만, 그 자체로도 까다로운 작업이기도 합니다. 도메인 또는 목적에 특화되도록 개체명 인식을 정확하게 하는 방법 중 하나는 기존에 공개된 개체명 인식기를 사용하는 것이 아니라, 직접 목적에 맞는 데이터를 준비하여 기계를 훈련시켜 모델을 만드는 방법입니다. 여기서는 양방향 LSTM을 이용해서 개체명 인식기를 만들어봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. BIO 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개체명 인식에서 코퍼스로부터 개체명을 인식하기 위한 방법으로는 여러 방법이 있지만, 여기서는 가장 보편적인 방법 중 하나인 IOB (또는 BIO) 방법을 소개합니다. B는 Begin의 약자로 개체명이 시작되는 부분, I는 Inside의 약자로 개체명의 내부 부분을 의미하며, O는 Outside의 약자로 개체명이 아닌 부분을 의미합니다.\n",
    "\n",
    "예를 들어서 영화에 대한 코퍼스 중에서 영화 제목에 대한 개체명을 뽑아내고 싶다고 가정합시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**해 B  \n",
    "리 I  \n",
    "포 I  \n",
    "터 I  \n",
    "보 O  \n",
    "러 O  \n",
    "가 O  \n",
    "자 O**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 영화 제목에 대해서만 개체명을 인식하는데, 영화 제목이 시작되는 글자인 '해'에서는 B가 사용되었고, 그리고 영화 제목이 끝나는 순간까지 I가 사용됩니다. 그리고 영화 제목이 아닌 부분에 대해서만 O가 사용됩니다. 이처럼 B와 I는 개체명을 위해 사용되고, O는 개체명이 아니라는 의미를 갖게 됩니다.\n",
    "\n",
    "물론 개체명 인식이라는 것은 보통 한 종류의 개체에 대해서만 언급하는 것이 아니라, 여러 종류의 개체가 있을 수 있습니다. 예를 들어 영화에 대한 대화에서는 영화 제목에 대한 개체명과 극장에 대한 개체명이 있을 수 있습니다. 그럴 때는, 각 개체가 어떤 종류인지도 함께 태깅이 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해 B-movie  \n",
    "리 I-movie  \n",
    "포 I-movie  \n",
    "터 I-movie  \n",
    "보 O  \n",
    "러 O  \n",
    "메 B-theater  \n",
    "가 I-theater  \n",
    "박 I-theater  \n",
    "스 I-theater  \n",
    "가 O  \n",
    "자 O  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 개체명 인식 데이터 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 실습을 통해 양방향 LSTM을 이용한 개체명 인식에 대해서 더 자세히 알아보도록 하겠습니다. CONLL2003은 개체명 인식을 위한 전통적인 영어 데이터 셋입니다. 해당 데이터를 가지고 훈련하여 개체명 인식 모델을 만들어보겠습니다.\n",
    "\n",
    "다운로드 링크 : https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/neuroner/data/conll2003/en/train.txt\n",
    "전체 데이터는 위 링크에서 train.txt 파일을 다운로드 받을 수 있습니다.\n",
    "\n",
    "해당 데이터의 앞 부분을 일부 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EU NNP B-NP B-ORG  \n",
    "rejects VBZ B-VP O  \n",
    "German JJ B-NP B-MISC  \n",
    "call NN I-NP O  \n",
    "to TO B-VP O  \n",
    "boycott VB I-VP O  \n",
    "British JJ B-NP B-MISC  \n",
    "lamb NN I-NP O  \n",
    ". . O O  \n",
    "  \n",
    "Peter NNP B-NP B-PER  \n",
    "Blackburn NNP I-NP I-PER  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 형식은 [단어] [품사 태깅] [청크 태깅] [개체명 태깅]의 형식으로 되어있습니다.\n",
    "\n",
    "품사 태깅이 의미하는 바는 아래 링크에서 자세하게 확인할 수 있는데, 예를 들어서 EU 옆에 붙어있는 NNP는 고유 명사 단수형을 의미하며, rejects 옆에 있는 VBZ는 3인칭 단수 동사 현재형을 의미합니다.\n",
    "https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "개체명 태깅의 경우에는 LOC는 location, ORG는 organization, PER은 person, MISC는 miscellaneous를 의미합니다. 해당 데이터는 BIO 표현 방법을 사용하고 있기 때문에, 개체명의 시작 부분이면서 Organization을 의미하는 German에는 B-ORG라는 개체명 태깅이 붙습니다. 다만, German 그 자체로 개체명 하나이기 때문에 거기서 개체명 인식은 종료되면서 뒤에 I가 별도로 붙는 단어가 나오지는 않았습니다. 이에 German 뒤에 나오는 call은 개체명이 아니기 때문에 O가 태깅이 됩니다.\n",
    "\n",
    "또 하나 기억해두어야할 것은 9번째 줄인. . O O 다음에 11번째 줄 Peter가 나오는 부분 사이에서 10번째 줄은 공란으로 되어 있는데, 이는 9번째 줄에서 문장이 끝나고 11번째 줄에서 새로운 문장이 시작됨을 의미합니다.\n",
    "\n",
    "그 다음 문장이 시작되는 11번째 줄에서는 개체명이 하나의 단어로 끝나지 않았을 때, 어떻게 다음 단어로 개체명 인식이 이어지는지를 보여줍니다. Peter는 개체명이 시작되면서 person에 해당되기 때문에 B-PER이라는 개체명 태깅이 붙습니다. 그리고 아직 개체명에 대한 인식은 끝나지 않았기 때문에 뒤에 붙는 Blackburn에서는 I가 나오면서 I-PER이 개체명 태깅으로 붙게 됩니다. 즉, Peter Blackburn이 person에 속하는 하나의 개체명입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 양방향 LSTM을 이용해서 개체명 인식 태깅을 하는 모델을 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 설명한 개체명 인식 데이터를 읽어 전처리를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('train.txt', 'r')\n",
    "tagged_sentences = []\n",
    "sentence = []\n",
    "\n",
    "for line in f:\n",
    "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
    "        if len(sentence) > 0:\n",
    "            tagged_sentences.append(sentence)\n",
    "            sentence = []\n",
    "        continue\n",
    "    splits = line.split(' ') # 공백을 기준으로 속성을 구분한다.\n",
    "    splits[-1] = re.sub(r'\\n', '', splits[-1]) # 줄바꿈 표시 \\n을 제거한다.\n",
    "    word = splits[0].lower() # 단어들은 소문자로 바꿔서 저장한다.\n",
    "    sentence.append([word, splits[-1]]) # 단어와 개체명 태깅만 기록한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 샘플 개수를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 개수:  14041\n"
     ]
    }
   ],
   "source": [
    "print(\"전체 샘플 개수: \", len(tagged_sentences)) # 전체 샘플의 개수 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 중 첫번째 샘플만 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['eu', 'B-ORG'], ['rejects', 'O'], ['german', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['british', 'B-MISC'], ['lamb', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0]) # 첫번째 샘플 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리가 수행된 첫번째 샘플이 출력된 것을 볼 수 있습니다. 이러한 샘플이 총 14,041개가 있습니다. 그런데 훈련을 시키려면 훈련 데이터에서 단어에 해당되는 부분과 개체명 태깅 정보에 해당되는 부분을 분리시켜야 합니다. 즉, [('eu', 'B-ORG'), ('rejects', 'O')]와 같은 문장 샘플이 있다면 eu와 rejects는 같이 저장하고, B-ORG와 O를 같이 저장할 필요가 있습니다.\n",
    "\n",
    "이런 경우 파이썬 함수 중에서 zip()함수가 유용한 역할을 합니다. zip()함수는 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할을 합니다. (2챕터의 데이터의 분리 챕터 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, ner_tags = [], [] \n",
    "for tagged_sentence in tagged_sentences: # 14,041개의 문장 샘플을 1개씩 불러온다.\n",
    "    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n",
    "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
    "    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 문장 샘플에 대해서 단어는 sentences에 태깅 정보는 ner_tags에 저장하였습니다. 임의로 첫번째 문장 샘플을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
      "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(ner_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 샘플에 대해서 단어에 대해서만 sentences[0]에, 또한 개체명에 대해서만 ner_tags[0]에 저장된 것을 볼 수 있습니다. 뒤에서 보겠지만, sentences는 예측을 위한 X에 해당되며 ner_tags는 예측 대상인 y에 해당됩니다. 다른 샘플들에 대해서도 처리가 되었는지 확인하기 위해 임의로 13번째 샘플에 대해서도 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['only', 'france', 'and', 'britain', 'backed', 'fischler', \"'s\", 'proposal', '.']\n",
      "['O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-PER', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[12])\n",
    "print(ner_tags[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어에 대해서만 sentences[12]에, 또한 개체명에 대해서만 ner_tags[12]에 저장된 것을 확인할 수 있습니다. 또한 첫번째 샘플과 길이가 다른 것을 볼 수 있습니다. 사실 14,041개의 문장 샘플의 길이는 전부 제각각입니다. 전체 데이터의 길이 분포를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 113\n",
      "샘플의 평균 길이 : 14.501887\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
    "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그래프는 샘플들의 길이가 대체적으로 0~40의 길이를 가지며, 특히 0~20의 길이를 가진 샘플이 상당한 비율을 차지하는 것을 보여줍니다. 길이가 가장 긴 샘플의 길이는 113입니다. 이제 케라스 토크나이저를 통해서 토큰화와 정수 인코딩을 진행합니다. 이번에는 문장 데이터에 있는 모든 단어를 사용하지 않고 높은 빈도수를 가진 상위 약 4,000개의 단어만을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 4000\n",
    "src_tokenizer = Tokenizer(num_words=max_words, oov_token='OOV')\n",
    "src_tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 데이터에 대해서는 src_tokenizer를, 레이블에 해당되는 개체명 태깅 정보에 대해서는 tar_tokenizer를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 4000\n",
      "개체명 태깅 정보 집합의 크기 : 10\n"
     ]
    }
   ],
   "source": [
    "vocab_size = max_words\n",
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 정수 인코딩을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tar_tokenizer.texts_to_sequences(ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 문장 데이터에 대해서 정수 인코딩이 수행된 결과는 X_train, 개체명 태깅 데이터에 대해서 정수 인코딩이 수행된 결과는 y_train에 저장되었습니다. 정수 인코딩이 되었는지 확인을 위해 임의로 첫번째 데이터를 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[989, 1, 205, 629, 7, 3939, 216, 1, 3]\n",
      "[4, 1, 7, 1, 1, 1, 7, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 문장 데이터에 대해서는 일부 단어가 'OOV'로 대체된 상황입니다. 이를 확인하기 위해 다시 디코딩(정수에서 다시 텍스트 데이터로 변환) 작업을 해보겠습니다. 이를 위해 인덱스로부터 단어를 리턴하는 index_to_word를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = src_tokenizer.index_word\n",
    "index_to_ner = tar_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정수 인코딩 된 첫번째 문장을 다시 디코딩해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 문장 : ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
      "빈도수가 낮은 단어가 OOV 처리된 문장 : ['eu', 'OOV', 'german', 'call', 'to', 'boycott', 'british', 'OOV', '.']\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for index in X_train[0] : # 첫번째 샘플 안의 인덱스들에 대해서\n",
    "    decoded.append(index_to_word[index]) # 다시 단어로 변환\n",
    "\n",
    "print('기존 문장 : {}'.format(sentences[0]))\n",
    "print('빈도수가 낮은 단어가 OOV 처리된 문장 : {}'.format(decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 본 그래프에 따르면, 대부분의 샘플은 길이가 70 이내입니다. X에 해당되는 데이터 X_train의 샘플들과 y에 해당되는 데이터 y_train 샘플들의 모든 길이를 임의로 70정도로 맞추어 보겠습니다. 이를 위해서 케라스의 pad_sequences()를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "# X_train의 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움.\n",
    "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)\n",
    "# y_train의 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자0으로 채움."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 샘플의 길이가 70이 되었습니다. 이제 훈련 데이터와 테스트 데이터를 8:2의 비율로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블에 해당하는 태깅 정보에 대해서 원-핫 인코딩을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test, num_classes=tag_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 각 데이터에 대한 크기를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기 : (11232, 70)\n",
      "훈련 샘플 레이블의 크기 : (11232, 70, 10)\n",
      "테스트 샘플 문장의 크기 : (2809, 70)\n",
      "테스트 샘플 레이블의 크기 : (2809, 70, 10)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 양방향 LSTM(Bi-directional LSTM)으로 개체명 인식기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 설계를 위한 필요한 도구들을 임포트하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many-to-Many 문제이므로 LSTM()에 return_sequences=True를 설정해준 것을 볼 수 있습니다. 또한, 이번 실습과 같이 각 데이터의 길이가 달라서 패딩을 하느라 숫자 0이 많아질 경우에는 Embedding()에 mask_zero=True를 설정하여 데이터에서 숫자 0은 패딩을 의미하므로 연산에서 제외시킨다는 옵션을 줄 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "88/88 [==============================] - 14s 87ms/step - loss: 0.2583 - accuracy: 0.7868 - val_loss: 0.1250 - val_accuracy: 0.8325\n",
      "Epoch 2/8\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.1081 - accuracy: 0.8441 - val_loss: 0.0739 - val_accuracy: 0.8888\n",
      "Epoch 3/8\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 0.0687 - accuracy: 0.8966 - val_loss: 0.0533 - val_accuracy: 0.9241\n",
      "Epoch 4/8\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 0.0485 - accuracy: 0.9311 - val_loss: 0.0403 - val_accuracy: 0.9432\n",
      "Epoch 5/8\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 0.0346 - accuracy: 0.9509 - val_loss: 0.0347 - val_accuracy: 0.9515\n",
      "Epoch 6/8\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.0295 - accuracy: 0.9591 - val_loss: 0.0322 - val_accuracy: 0.9547\n",
      "Epoch 7/8\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 0.0243 - accuracy: 0.9652 - val_loss: 0.0327 - val_accuracy: 0.9562\n",
      "Epoch 8/8\n",
      "88/88 [==============================] - 7s 77ms/step - loss: 0.0209 - accuracy: 0.9702 - val_loss: 0.0315 - val_accuracy: 0.9574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a15fe7f940>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=8,  validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 2s 18ms/step - loss: 0.0315 - accuracy: 0.9574\n",
      "\n",
      " 테스트 정확도: 0.9574\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 맞추고 있는지를 테스트 데이터를 주고 직접 실제값과 비교해보도록 하겠습니다. 앞서 만들어둔 인덱스로부터 단어와 개체명 태깅 정보를 리턴하는 index_to_word와 index_to_ner를 사용하여 테스트 데이터에 대한 예측값과 실제값을 비교 출력하도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "sarah            : B-PER   B-PER\n",
      "brady            : I-PER   I-PER\n",
      ",                : O       O\n",
      "whose            : O       O\n",
      "republican       : B-MISC  B-MISC\n",
      "husband          : O       O\n",
      "was              : O       O\n",
      "OOV              : O       O\n",
      "OOV              : O       O\n",
      "in               : O       O\n",
      "an               : O       O\n",
      "OOV              : O       O\n",
      "attempt          : O       O\n",
      "on               : O       O\n",
      "president        : O       O\n",
      "ronald           : B-PER   B-PER\n",
      "reagan           : I-PER   I-PER\n",
      ",                : O       O\n",
      "took             : O       O\n",
      "centre           : O       O\n",
      "stage            : O       O\n",
      "at               : O       O\n",
      "the              : O       O\n",
      "democratic       : B-MISC  B-MISC\n",
      "national         : I-MISC  I-MISC\n",
      "convention       : I-MISC  I-MISC\n",
      "on               : O       O\n",
      "monday           : O       O\n",
      "night            : O       O\n",
      "to               : O       O\n",
      "OOV              : O       O\n",
      "president        : O       O\n",
      "bill             : B-PER   B-PER\n",
      "clinton          : I-PER   I-PER\n",
      "'s               : O       O\n",
      "gun              : O       O\n",
      "control          : O       O\n",
      "efforts          : O       O\n",
      ".                : O       O\n"
     ]
    }
   ],
   "source": [
    "i=10 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = np.argmax(y_predicted, axis=-1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
    "true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
    "    if w != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t].upper(), index_to_ner[pred].upper()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도를 계산하고, 테스트용 샘플에 대해서 예측한 개체명도 출력해보았습니다. 출력 결과는 그럴듯해 보이지만 사실 이번에 사용한 정확도 측정 방법이 그다지 적절하지는 않았습니다. 대부분의 단어가 개체명이 아니라는 'O'가 태깅된 상황에서 예측 정확도가 수많은 'O'로 인해 결정되고 있기 때문입니다. 이를 해결하는 방법으로는 여러가지가 있겠지만, 그 중 한 가지는 F1-score를 도입하는 것입니다. 이에 대해서는 양방향 LSTM과 CRF 챕터에서 배웁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 양방향 LSTM을 이용한 품사 태깅(Part-of-speech Tagging using Bi-LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "품사 태깅에 대해서는 이미 2챕터의 토큰화 챕터에서 배운 바 있습니다. 그 당시에는 NLTK와 KoNLPy를 이용해서 이미 기존에 있는 모델로 품사 태깅을 수행하였지만, 여기서는 직접 양방향 LSTM을 이용한 품사 태깅을 수행하는 모델을 만들어보도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 품사 태깅 데이터에 대한 이해와 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 양방향 LSTM을 이용해서 품사 태깅을 하는 모델을 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK를 이용하면 영어 코퍼스에 토큰화와 품사 태깅 전처리를 진행한 문장 데이터를 받아올 수 있습니다. 여기서는 해당 데이터를 훈련시켜 품사 태깅을 수행하는 모델을 만들어보겠습니다. 우선 전체 문장 샘플의 개수를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품사 태깅이 된 문장 개수:  3914\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences = nltk.corpus.treebank.tagged_sents() # 토큰화에 품사 태깅이 된 데이터 받아오기\n",
    "print(\"품사 태깅이 된 문장 개수: \", len(tagged_sentences)) # 문장 샘플의 개수 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 중 첫번째 샘플만 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0]) # 첫번째 샘플 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "품사 태깅 전처리가 수행된 첫번째 문장이 출력된 것을 볼 수 있습니다. 이러한 문장 샘플이 총 3,914개가 있습니다. 그런데 훈련을 시키려면 훈련 데이터에서 단어에 해당되는 부분과 품사 태깅 정보에 해당되는 부분을 분리시켜야 합니다. 즉, [('Pierre', 'NNP'), ('Vinken', 'NNP')]와 같은 문장 샘플이 있다면 Pierre과 Vinken을 같이 저장하고, NNP와 NNP를 같이 저장할 필요가 있습니다.\n",
    "\n",
    "이런 경우 파이썬 함수 중에서 zip()함수가 유용한 역할을 합니다. zip()함수는 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할을 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, pos_tags = [], [] \n",
    "for tagged_sentence in tagged_sentences: # 3,914개의 문장 샘플을 1개씩 불러온다.\n",
    "    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 품사 태깅 정보들은 tag_info에 저장한다.\n",
    "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
    "    pos_tags.append(list(tag_info)) # 각 샘플에서 품사 태깅 정보만 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 문장 샘플에 대해서 단어는 sentences에 태깅 정보는 pos_tags에 저장하였습니다. 임의로 첫번째 문장 샘플을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
      "['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(pos_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 샘플에 대해서 단어에 대해서만 sentences[0]에, 또한 품사에 대해서만 pos_tags[0]에 저장된 것을 볼 수 있습니다. 뒤에서 보겠지만, sentences는 예측을 위한 X에 해당되며 pos_tags는 예측 대상인 y에 해당됩니다. 다른 샘플들에 대해서도 처리가 되었는지 확인하기 위해 임의로 아홉번째 샘플에 대해서도 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', \"'re\", 'talking', 'about', 'years', 'ago', 'before', 'anyone', 'heard', 'of', 'asbestos', 'having', 'any', 'questionable', 'properties', '.']\n",
      "['PRP', 'VBP', 'VBG', 'IN', 'NNS', 'IN', 'IN', 'NN', 'VBD', 'IN', 'NN', 'VBG', 'DT', 'JJ', 'NNS', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[8])\n",
    "print(pos_tags[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어에 대해서만 sentences[8]에, 또한 품사에 대해서만 pos_tags[8]에 저장된 것을 확인할 수 있습니다. 또한 첫번째 샘플과 길이가 다른 것을 볼 수 있습니다. 사실 3,914개의 문장 샘플의 길이는 전부 제각각입니다. 전체 데이터의 길이 분포를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 271\n",
      "샘플의 평균 길이 : 25.722024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
    "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그래프는 대부분의 샘플의 길이가 150 이내며 대부분 0~50의 길이를 가지는 것을 보여줍니다. 이제 케라스 토크나이저를 통해서 정수 인코딩을 진행합니다. 우선 케라스 토크나이저를 다음과 같이 함수로 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(samples):\n",
    "  tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(samples)\n",
    "  return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 데이터에 대해서는 src_tokenizer를, 레이블에 해당되는 품사 태깅 정보에 대해서는 tar_tokenizer를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = tokenize(sentences)\n",
    "tar_tokenizer = tokenize(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 집합과 품사 태깅 정보 집합의 크기를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 11388\n",
      "태깅 정보 집합의 크기 : 47\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(src_tokenizer.word_index) + 1\n",
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('태깅 정보 집합의 크기 : {}'.format(tag_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 정수 인코딩을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tar_tokenizer.texts_to_sequences(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 문장 데이터에 대해서 정수 인코딩이 수행된 결과는 X_train, 품사 태깅 데이터에 대해서 정수 인코딩이 수행된 결과는 y_train에 저장되었습니다. 정수 인코딩이 되었는지 확인을 위해 임의로 세번째 데이터를 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5601, 3746, 1, 2024, 86, 331, 1, 46, 2405, 2, 131, 27, 6, 2025, 332, 459, 2026, 3], [31, 3746, 20, 177, 4, 5602, 2915, 1, 2, 2916, 637, 147, 3]]\n",
      "[[3, 3, 8, 10, 6, 7, 8, 21, 13, 4, 1, 2, 4, 7, 1, 3, 10, 9], [3, 3, 17, 1, 2, 3, 3, 8, 4, 3, 19, 1, 9]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:2])\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 본 그래프에 따르면, 대부분의 샘플은 길이가 150 이내입니다. X에 해당되는 데이터 X_train의 샘플들과 y에 해당되는 데이터 y_train 샘플들의 모든 길이를 임의로 150정도로 맞추어 보겠습니다. 이를 위해서 케라스의 pad_sequences()를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "# X_train의 모든 샘플의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움.\n",
    "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)\n",
    "# y_train의 모든 샘플의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 샘플의 길이가 150이 되었습니다. 이제 훈련 데이터와 테스트 데이터를 8:2의 비율로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블에 해당하는 태깅 정보에 대해서 원-핫 인코딩을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test, num_classes=tag_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 각 데이터에 대한 크기를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기 : (3131, 150)\n",
      "훈련 샘플 레이블의 크기 : (3131, 150, 47)\n",
      "테스트 샘플 문장의 크기 : (783, 150)\n",
      "테스트 샘플 레이블의 크기 : (783, 150, 47)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 양방향 LSTM(Bi-directional LSTM)으로 POS Tagger 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "25/25 [==============================] - 12s 216ms/step - loss: 0.6098 - accuracy: 0.1323 - val_loss: 0.5073 - val_accuracy: 0.1630\n",
      "Epoch 2/6\n",
      "25/25 [==============================] - 2s 93ms/step - loss: 0.5051 - accuracy: 0.1741 - val_loss: 0.4677 - val_accuracy: 0.3104\n",
      "Epoch 3/6\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.4460 - accuracy: 0.3739 - val_loss: 0.3405 - val_accuracy: 0.4891\n",
      "Epoch 4/6\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.3077 - accuracy: 0.5488 - val_loss: 0.2026 - val_accuracy: 0.7024\n",
      "Epoch 5/6\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 0.1735 - accuracy: 0.7633 - val_loss: 0.1088 - val_accuracy: 0.8517\n",
      "Epoch 6/6\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 0.0839 - accuracy: 0.8973 - val_loss: 0.0676 - val_accuracy: 0.8993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f52b7d1c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=6,  validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 19ms/step - loss: 0.0676 - accuracy: 0.8993\n",
      "\n",
      " 테스트 정확도: 0.8993\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 맞추고 있는지를 특정 테스트 데이터를 주고 직접 출력해서 확인해보겠습니다. 우선 인덱스로부터 단어와 품사 태깅 정보를 리턴하는 index_to_word와 index_to_tag를 만들고 이를 이용하여 실제값과 예측값을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "in               : IN      IN\n",
      "addition         : NN      NN\n",
      ",                : ,       ,\n",
      "buick            : NNP     NNP\n",
      "is               : VBZ     VBZ\n",
      "a                : DT      DT\n",
      "relatively       : RB      RB\n",
      "respected        : VBN     VBN\n",
      "nameplate        : NN      NN\n",
      "among            : IN      IN\n",
      "american         : NNP     NNP\n",
      "express          : NNP     NNP\n",
      "card             : NN      NN\n",
      "holders          : NNS     NNS\n",
      ",                : ,       ,\n",
      "says             : VBZ     VBZ\n",
      "0                : -NONE-  -NONE-\n",
      "*t*-1            : -NONE-  -NONE-\n",
      "an               : DT      DT\n",
      "american         : NNP     NNP\n",
      "express          : NNP     NNP\n",
      "spokeswoman      : NN      NN\n",
      ".                : .       .\n"
     ]
    }
   ],
   "source": [
    "index_to_word=src_tokenizer.index_word\n",
    "index_to_tag=tar_tokenizer.index_word\n",
    "\n",
    "i=10 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = np.argmax(y_predicted, axis=-1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
    "true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
    "    if w != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_tag[t].upper(), index_to_tag[pred].upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
